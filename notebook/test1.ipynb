{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h3> Removing top layer of efficient net and loading our own classification layer</h3>\n",
    "\n",
    "references:<br>\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/\">Tensorflow Documentation - Layers</a><br>\n",
    "<a href=\"https://arxiv.org/pdf/1905.11946.pdf\">Efficient Net and how it works</a><br>\n",
    "<a href=\"https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/\">Keras example for fine tuning</a><br>\n",
    "<a href=\"https://www.tensorflow.org/guide/keras/train_and_evaluate\">Tensorflow Documentation - Compiling and Evaluating</a><br>\n",
    "<a href=\"https://keras.io/api/optimizers/\">Keras Documentation - Optimisers</a><br>\n",
    "<a href=\"https://keras.io/api/metrics/\">Keras Documentation - Metrics</a><br>\n",
    "<a href=\"https://keras.io/api/losses/\">Keras Documentation - Losses</a><br>\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0 as enet\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# loading pretrained model, setting input shape\n",
    "inputs = (224, 224, 3)\n",
    "\n",
    "# Selecting a topless model (sounds damn good...)\n",
    "basemodel = enet(include_top=False, input_shape=inputs, weights=\"imagenet\")\n",
    "\n",
    "# locking the trained weights (freezing?)\n",
    "basemodel.trainable = False \n",
    "\n",
    "# checking out how its like\n",
    "basemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to rebuild top layer for our own classification\n",
    "\n",
    "dropout_rate = 0.1 #i_dunno_yet - supposed to prevent overfit\n",
    "types = 2 #currently only mask and no mask \n",
    "\n",
    "# building up the model in sequence\n",
    "model = models.Sequential()\n",
    "\n",
    "# loading the original topless model\n",
    "model.add(basemodel)\n",
    "\n",
    "# adding global pooling 2d to remove the columns and rows output from previous layer\n",
    "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
    "\n",
    "# adding the dropout and subsequently the softmax layer\n",
    "model.add(layers.Dropout(dropout_rate, name=\"drout\"))\n",
    "model.add(layers.Dense(types, activation=\"softmax\", name=\"classdense\"))\n",
    "\n",
    "# view the assembled model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(whole_list, unique, filter, list_pos):\n",
    "\n",
    "    ret_list = []\n",
    "    dsize = len(whole_list)\n",
    "    \n",
    "    # handle use cases\n",
    "    if list_pos == 0 or list_pos > 2:\n",
    "        print(\"Invalid parameter call - return NULL\")\n",
    "        return    # not needed - do nothing\n",
    "    elif list_pos == 1:    # extract directories\n",
    "         for record in range(0,dsize):\n",
    "            item = whole_list[record][list_pos]   # list item to extract [depth,path,filename]\n",
    "            if unique:   # process unique paths\n",
    "                if item not in ret_list:   # check if already added\n",
    "                    ret_list.append(item)\n",
    "            else:\n",
    "                ret_list.append(item)\n",
    "    elif list_pos == 2:    # extract filenames\n",
    "        for record in range(0,dsize):\n",
    "            item = whole_list[record][list_pos]   # list item to extract [depth,path,filename]\n",
    "            if whole_list[record][1] == filter:\n",
    "                ret_list.append(item)   \n",
    "    \n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo - image preprocessing function (to check)\n",
    "\n",
    "def make_tf_dataset(all_files):\n",
    "    type_names = []\n",
    "    tf_img_array = []\n",
    "\n",
    "    dirlist = get_list(all_files, True, \"*\", 1)   # get unique directories\n",
    "    \n",
    "    for folder in dirlist:\n",
    "        for pic in os.listdir(folder):\n",
    "            image = os.path.join(folder, pic)\n",
    "            image = tf.io.read_file(image)\n",
    "            image = tf.io.decode_image(image, channels = 3, expand_animations = False)\n",
    "            image = tf.image.resize(image, (224, 224))\n",
    "            image = tf.cast(image / 255, tf.float32)\n",
    "            tf_img_array.append(image)\n",
    "            type_names.append(folder)\n",
    "    \n",
    "    type_dict = {k : v for v, k in enumerate(np.unique(type_names))}\n",
    "    target_class= [type_dict[type_names[i]] for i in range(len(type_names))]\n",
    "    tf_y = tf.cast(list(map(int, target_class)), tf.int32)\n",
    "\n",
    "    #debug - print(f\"dict = {type_dict}\\n targetclass = {target_class}\\n y= {tf_y}\")\n",
    "    return tf.stack(tf_img_array, axis = 0), tf_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from itertools import groupby\n",
    "# from operator import itemgetter\n",
    "\n",
    "# You traverse the tree twice. Not really necessary. The code essentially creates a list of tuples. \n",
    "# Each tuple contains the depth, the relative path, and the filename.\n",
    "# After that the list is sorted to have the deepest folder(s) first.\n",
    "# Following that the code groups the files by depth and relative path. \n",
    "# it is using the groupby method of the itertools method.\n",
    "\n",
    "def get_deepest_folders(path):\n",
    "\n",
    "    a_files = []\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            # print(\"Looking at\", file)\n",
    "            relativePath = os.path.relpath(root, path)\n",
    "            # print(\"In relative path\", relativePath, root, path)\n",
    "            if relativePath == \".\":\n",
    "                relativePath = \"\"\n",
    "            a_files.append(\n",
    "                (root.count(os.path.sep),\n",
    "                root,\n",
    "                file\n",
    "                )\n",
    "            )\n",
    "    return a_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(whole_list, sampling = 0):\n",
    "\n",
    "    # Code to display sample of the images\n",
    "    if sampling <=0:\n",
    "        return   # do nothing\n",
    "\n",
    "    dirlist = get_list(whole_list, True, \"*\", 1)   # get directories\n",
    "\n",
    "    foldersize = len(dirlist)\n",
    "    print(\"There are: \", foldersize, \" folders to be processed.\")\n",
    "\n",
    "    for directory in dirlist:\n",
    "        print(\"Current directory: \", directory, \"\\r\")\n",
    "        filenames = get_list(whole_list, False, directory, 2)   # get all filenames\n",
    "        \n",
    "        for i in range (0,sampling): \n",
    "            pil_im = Image.open(directory + \"/\" + filenames[i])\n",
    "            display(pil_im)\n",
    "            print(filenames[i])  \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting image folder\n",
    "\n",
    "media_folder = \"../data/training\"\n",
    "\n",
    "all_files = get_deepest_folders(media_folder)\n",
    "\n",
    "# display sample images from all subdirectories\n",
    "show_sample(all_files, 3) \n",
    " \n",
    "# executing the create image function, returns two \n",
    "\n",
    "\n",
    "tf_img_array, tf_y = make_tf_dataset(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compile the model (specifying optimser, loss and metrics) - I_dunno_need_adj_later\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95, epsilon=1e-07),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
    "    )\n",
    "\n",
    "\n",
    "# fitting the processed images into the model\n",
    "\n",
    "batch_size = 32\n",
    "epochs_to_run = 10\n",
    "\n",
    "print(\"Fit model on training data:\")\n",
    "history = model.fit(tf_img_array, tf_y, batch_size = batch_size, epochs = epochs_to_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: finetuning other layers of the pretrained model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: fit the training set into the fine-tuned model to see if theres improvements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: process validation data and validate model with validation data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: write entry script for web api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: packing up the model (docker) and deploy (it will be a nightmare)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: deploy model on cloud space, verify service is running\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to-do: test model (and profit)\n"
   ]
  }
 ]
}